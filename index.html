<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Anna Min</title>

    <meta name="author" content="Anna Min">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Anna Min      <span style="font-family: 'KaiTi', 'STKaiti', serif;">(闵安娜)</span>
                </p>
                <p>Hi, I am an undergraduate at <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>, who work on multi-modal learning.
                </p>
                <p>
                  I am fortunate to work with Prof. <a href="https://andrewowens.com/">Andrew Owens</a> from <a href="https://umich.edu/">University of Michigan</a> and Prof. <a href="https://hangzhaomit.github.io/">Hang Zhao</a> from <a href="https://iiis.tsinghua.edu.cn/en/">Tsinghua University </a>.
                </p>
                <p>
                  Email: anna.min1754 at gmail dot com
                </p>
                <p style="text-align:center">
                  <a href="mailto:anna.min1754@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/info/annamin-20231203-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/_AnnaMin">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/yangqing-20/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:20%;max-width:20%">
                <a href="images/info/AnnaMin.jpg"><img style="width:100%;max-width:100%;object-fit: cover;" alt="profile photo" src="images/info/AnnaMin.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research centers on the realm of multi-modal perception, with a particular focus on leveraging machine learning to create and evoke sensory experiences that resonate with individuals' past encounters or anticipated interactions. 
                  <br>
                  Previously, I have worked on combining vision and sound for spatial natural audio generation and emotional voice generation, to create an auditorily immersive environment for interaction. I am also interested in generative modeling for audio, music, and vision.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="camp_stop()" onmouseover="camp_start()">
              <td style="padding:20px;width:45%;vertical-align:middle">
                <div class="one">
                  <!-- <div class="two" id='camp_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/camp.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div> -->
                  <img src='images/paper/emotiontransfer.jpg' width="350">
                </div>
              </td>
              <td style="padding:20px;width:55%;vertical-align:middle">
                <a>
                  <span class="papertitle">Fine-grained Emotion Transfer for Speech-to-Speech Translation in Expressive Video Dubbing</span>
                </a>
                <br>
                <strong>Anna Min</strong>,
                <a href="https://huchenxucs.github.io/">Chenxu Hu</a>,
                <a href="https://rayeren.github.io/">Yi Ren</a>,
                <a href="https://hangzhaomit.github.io/">Hang Zhao</a>
                <br>
                <em>AAAI24 Workshop on Digital Human, Oral Presentation</em>
                <br>
                <em>in submission to NAACL2024</em>
                <br>
                <p></p>
                <p>
                  Construct a newly constructed dataset with aligned bilingual audio tracks and use wav to unit translation and unit to wav HiFi-GAN-based networks for transferring pitches and rhythms.
                </p>
              </td>
            </tr>


    <tr onmouseout="camp_stop()" onmouseover="camp_start()">
      <td style="padding:20px;width:45%;vertical-align:middle">
        <div class="one">
          <!-- <div class="two" id='camp_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/camp.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div> -->
          <img src='images/paper/cascaded.jpg' width="350">
        </div>
      </td>
      <td style="padding:20px;width:55%;vertical-align:middle">
        <a>
          <span class="papertitle">When End-to-End is Overkill: Rethinking Cascaded Speech-to-Text Translation</span>
        </a>
        <br>
        <strong>Anna Min</strong>,
        <a href="https://huchenxucs.github.io/">Chenxu Hu</a>,
        <a href="https://rayeren.github.io/">Yi Ren</a>,
        <a href="https://scholar.google.com/citations?user=e6_J-lEAAAAJ&hl=en">Xiang Yin</a>,
        <a href="https://hangzhaomit.github.io/">Hang Zhao</a>
        <br>
        <em>in submission to COLING2024</em>
        <br>
        <p></p>
        <p>
          Propose a method that leverages two distinct pretrained autoregressive models to enhance a cascaded system and address the challenges associated with error divergence.
        </p>
      </td>
    </tr>


          </tbody></table>

          <br><br>
          <br><br>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
                <p>
                  I am an amateur illustrator(Currently fascinated by generative models though).
                </p>
              </td>

            </tr>
          </tbody>
        
        </table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>


            
<tr>
  <td align="right">
    <p>
      Last updated Dec. 2023.
    </p>
    <p>
      Template from <a href="https://jonbarron.info/">Jonathan Barron</a>.
    </p>
  </td>
</tr>
          
            
            
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
